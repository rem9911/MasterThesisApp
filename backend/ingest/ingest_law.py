import os
import re
import psycopg2
from langchain_community.document_loaders import PyPDFLoader
# On utilise RecursiveCharacterTextSplitter qui est plus robuste
from langchain_text_splitters import RecursiveCharacterTextSplitter 
from sentence_transformers import SentenceTransformer

# --- CONFIGURATION ---
DB_HOST = os.getenv("POSTGRES_HOST", "192.168.1.3") 

DB_CONFIG = {
    "dbname": "legal_ai",
    "user": "legal_user",
    "password": "legal_pass_dev",
    "host": DB_HOST,
    "port": "5432"
}

SOURCE_FILE = "backend/data/code_consommation.pdf"
EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-0.6B"

def ingest_with_langchain():
    print(f"üöÄ D√©marrage de l'ingestion vers {DB_HOST}...")

    # 1. V√©rification du fichier
    if not os.path.exists(SOURCE_FILE):
        print(f"‚ùå ERREUR: Le fichier {SOURCE_FILE} est introuvable.")
        return

    # 2. Chargement du PDF
    print(f"üìÇ Chargement du PDF : {SOURCE_FILE}")
    try:
        loader = PyPDFLoader(SOURCE_FILE)
        pages = loader.load()
        print(f"   üìñ {len(pages)} pages lues.")
        
        # Fusion du texte pour ne pas couper un article au milieu d'une phrase entre deux pages
        full_text = "\n".join([p.page_content for p in pages])
        print(f"   üìù Taille totale : {len(full_text)} caract√®res.")
        
    except Exception as e:
        print(f"‚ùå Erreur lecture PDF : {e}")
        return

    # 3. D√©coupage (CORRECTION ICI)
    print("‚úÇÔ∏è D√©coupage des articles...")
    
    text_splitter = RecursiveCharacterTextSplitter(
        # Note le 's' √† separators et c'est une liste
        separators=[r"(?=\nArticle [L|R])"], 
        chunk_size=4000,
        chunk_overlap=0,
        keep_separator=True,
        is_separator_regex=True # INDISPENSABLE pour que le regex fonctionne
    )
    
    # CORRECTION ICI : on passe une liste contenant le texte complet √† create_documents
    split_docs = text_splitter.create_documents([full_text])
    print(f"‚úÖ {len(split_docs)} articles identifi√©s.")

    if len(split_docs) < 2:
        print("‚ö†Ô∏è Attention : Peu d'articles trouv√©s. V√©rifie que le PDF contient bien du texte s√©lectionnable.")

    # 4. Chargement du Mod√®le (Mac)
    print(f"üß† Chargement du mod√®le {EMBEDDING_MODEL}...")
    model = SentenceTransformer(EMBEDDING_MODEL, trust_remote_code=True, device="cpu")

    # 5. Connexion au Pi
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
    except Exception as e:
        print(f"‚ùå Connexion au Pi impossible ({DB_HOST}) : {e}")
        return

    print("üßπ Nettoyage de la table existante...")
    cur.execute("TRUNCATE TABLE legal_articles;")
    
    count = 0
    print("üåä Envoi des donn√©es vers le Pi...")
    
    for doc in split_docs:
        content = doc.page_content.strip()
        
        if len(content) < 50: continue

        # Extraction du num√©ro d'article
        # On cherche dans les 200 premiers caract√®res du chunk
        header = content[:200]
        
        # Regex am√©lior√© pour capturer "Article L. 123" ou "Article L123"
        match = re.search(r"Article\s+([L|R]\.?\s*\d+[-]\d+[a-zA-Z]?)", header, re.IGNORECASE)
        
        if match:
            # Nettoyage : "L. 123-1" -> "L123-1"
            article_number = match.group(1).replace(" ", "").replace(".", "")
        else:
            # Si on ne trouve pas de num√©ro au d√©but, c'est peut-√™tre un morceau de texte orphelin
            # On peut soit l'ignorer, soit le marquer. Ici on l'ignore pour la propret√©.
            continue

        vector = model.encode(content).tolist()
        metadata = '{"source": "Code Consommation PDF", "type": "loi"}'

        sql = """
            INSERT INTO legal_articles 
            (article_number, content, metadata, embedding, content_search, code_source)
            VALUES (%s, %s, %s, %s, to_tsvector('french', %s), %s);
        """
        cur.execute(sql, (
            article_number, content, metadata, vector, content, "Code Consommation"
        ))
        count += 1
        if count % 10 == 0:
            print(f"   üíæ {count} articles ins√©r√©s...", end='\r')

    conn.commit()
    cur.close()
    conn.close()
    print(f"\nüéâ SUCC√àS ! {count} articles ing√©r√©s sur le Raspberry Pi.")

if __name__ == "__main__":
    ingest_with_langchain()